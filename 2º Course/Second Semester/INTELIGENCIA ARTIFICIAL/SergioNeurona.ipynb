{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto Redes Neuronales. Compración Perceptrón simple vs Perceptrón multicapa en  clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según los CDC, las enfermedades del corazón son una de las principales causas de muerte. Aproximadamente la mitad de los estadounidenses (47%) presentan al menos uno de los tres factores de riesgo clave de las enfermedades cardíacas: presión arterial alta, colesterol alto y tabaquismo. Otros indicadores clave son la condición de diabético, la obesidad (IMC elevado), la falta de actividad física o el consumo excesivo de alcohol. Detectar y prevenir los factores que más influyen en las enfermedades del corazón es muy importante en la asistencia sanitaria. Los avances informáticos, por su parte, permiten aplicar métodos de aprendizaje automático para detectar \"patrones\" a partir de los datos que puedan predecir el estado de un paciente.\n",
    "\n",
    "En este proyecto vas a **comparar la eficacia de dos métodos diferentes en la predicción del riesgo de padecer una enfermedad cardiaca**. \n",
    "\n",
    "El conjunto de datos procede de los CDC y es una parte importante del Sistema de Vigilancia de los Factores de Riesgo en el Comportamiento, que realiza encuestas telefónicas anuales para recopilar datos sobre el estado de salud de los residentes en EE.UU. El dataset original tiene casi 300 variables, pero se ha reducido a sólo unas 20 variables. \n",
    "\n",
    "Tienes que realizar las siguientes tareas:\n",
    "    - Crear una función perceptron simple que dado un ejemplo o conjunto de ejemplos devuelva la clase predicha (-1, 1).\n",
    "    - Crear una función para calcular el coste 'bisagra' para medir el error en clasificación.\n",
    "    - Crear una función que calcule el gradiente de la función de coste por cada variable del perceptrón.\n",
    "    - Programar el algortimo del descenso con gradiente y obtener los parámetros del perceptrón que mejor se ajusten a los datos de entrenamiento.\n",
    "    - Calcular la matriz de confusión en los ejemplos de test.\n",
    "    - Utilizando la librería sklearn entrenar 2 arquitecturas diferentes de redes neuronales.\n",
    "    - Comparar las matrices de confusión de las Redes Neuronales con al obtenida por el perceptrón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda se leen los datos y se generan los conjuntos de entrenamiento y de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "      <th>BMI</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8739</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12022</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5817</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HeartDisease  Smoking  AlcoholDrinking  Stroke  DiffWalking  Sex  \\\n",
       "8739              0        1                0       0            0    0   \n",
       "12022             0        1                0       0            0    1   \n",
       "5817              0        0                0       0            0    1   \n",
       "13835             0        0                0       0            0    1   \n",
       "2949              0        1                0       0            1    0   \n",
       "\n",
       "       AgeCategory  Race  Diabetic  PhysicalActivity  GenHealth  Asthma  \\\n",
       "8739             4     2         0                 1          1       1   \n",
       "12022            9     5         0                 1          4       0   \n",
       "5817             2     5         0                 1          0       0   \n",
       "13835           10     4         1                 1          2       0   \n",
       "2949            10     5         0                 1          4       0   \n",
       "\n",
       "       KidneyDisease  SkinCancer    BMI  PhysicalHealth  MentalHealth  \\\n",
       "8739               0           0  39.06            30.0          15.0   \n",
       "12022              0           0  26.69             0.0           0.0   \n",
       "5817               0           0  21.52             0.0           0.0   \n",
       "13835              0           0  28.13             0.0           0.0   \n",
       "2949               0           1  42.27             0.0           1.0   \n",
       "\n",
       "       SleepTime  \n",
       "8739         5.0  \n",
       "12022        8.0  \n",
       "5817         5.0  \n",
       "13835        6.0  \n",
       "2949         7.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "datos = pd.read_csv(\"heart_2020.csv\")\n",
    "datos = datos.drop(['Unnamed: 0'], axis=1)\n",
    "datos = shuffle(datos)\n",
    "datos.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "      <th>BMI</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.00000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.456217</td>\n",
       "      <td>0.49335</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>0.087117</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.523233</td>\n",
       "      <td>7.620233</td>\n",
       "      <td>4.611650</td>\n",
       "      <td>0.458683</td>\n",
       "      <td>0.719467</td>\n",
       "      <td>2.231617</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>0.073217</td>\n",
       "      <td>0.127967</td>\n",
       "      <td>28.971355</td>\n",
       "      <td>5.141217</td>\n",
       "      <td>4.201083</td>\n",
       "      <td>7.118750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498083</td>\n",
       "      <td>0.49996</td>\n",
       "      <td>0.237767</td>\n",
       "      <td>0.282008</td>\n",
       "      <td>0.420643</td>\n",
       "      <td>0.499464</td>\n",
       "      <td>3.413152</td>\n",
       "      <td>1.024753</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.449264</td>\n",
       "      <td>1.396139</td>\n",
       "      <td>0.356616</td>\n",
       "      <td>0.260494</td>\n",
       "      <td>0.334055</td>\n",
       "      <td>6.541266</td>\n",
       "      <td>9.761226</td>\n",
       "      <td>8.466793</td>\n",
       "      <td>1.571938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.210000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.280000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.970000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HeartDisease      Smoking  AlcoholDrinking        Stroke   DiffWalking  \\\n",
       "count  60000.000000  60000.00000     60000.000000  60000.000000  60000.000000   \n",
       "mean       0.456217      0.49335         0.060150      0.087117      0.229700   \n",
       "std        0.498083      0.49996         0.237767      0.282008      0.420643   \n",
       "min        0.000000      0.00000         0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.00000         0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.00000         0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.00000         0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.00000         1.000000      1.000000      1.000000   \n",
       "\n",
       "                Sex   AgeCategory          Race      Diabetic  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.523233      7.620233      4.611650      0.458683   \n",
       "std        0.499464      3.413152      1.024753      0.838951   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      5.000000      5.000000      0.000000   \n",
       "50%        1.000000      8.000000      5.000000      0.000000   \n",
       "75%        1.000000     10.000000      5.000000      0.000000   \n",
       "max        1.000000     12.000000      5.000000      3.000000   \n",
       "\n",
       "       PhysicalActivity     GenHealth        Asthma  KidneyDisease  \\\n",
       "count      60000.000000  60000.000000  60000.000000   60000.000000   \n",
       "mean           0.719467      2.231617      0.149533       0.073217   \n",
       "std            0.449264      1.396139      0.356616       0.260494   \n",
       "min            0.000000      0.000000      0.000000       0.000000   \n",
       "25%            0.000000      1.000000      0.000000       0.000000   \n",
       "50%            1.000000      2.000000      0.000000       0.000000   \n",
       "75%            1.000000      4.000000      0.000000       0.000000   \n",
       "max            1.000000      4.000000      1.000000       1.000000   \n",
       "\n",
       "         SkinCancer           BMI  PhysicalHealth  MentalHealth     SleepTime  \n",
       "count  60000.000000  60000.000000    60000.000000  60000.000000  60000.000000  \n",
       "mean       0.127967     28.971355        5.141217      4.201083      7.118750  \n",
       "std        0.334055      6.541266        9.761226      8.466793      1.571938  \n",
       "min        0.000000     12.210000        0.000000      0.000000      1.000000  \n",
       "25%        0.000000     24.410000        0.000000      0.000000      6.000000  \n",
       "50%        0.000000     27.920000        0.000000      0.000000      7.000000  \n",
       "75%        0.000000     32.280000        4.000000      3.000000      8.000000  \n",
       "max        1.000000     93.970000       30.000000     30.000000     24.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Ten en cuenta que la variable y tiene valores (0 y 1)\n",
    "\n",
    "y = np.array(datos['HeartDisease'])\n",
    "y[y==0] = -1\n",
    "datos = datos.drop(['HeartDisease'], axis=1)\n",
    "X = np.array(datos)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2, random_state= 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería sklearn tiene implementada una clase MLPClassifier que es un perceptrón multicapa con el algoritmo de backpropagation que podemos utilizar en la siguiente celda se crea un preceptrón con una capa oculta y dos neuronas para que se ajuste a la función XOR.\n",
    "Para ayuda sobre la clase y sus parámetros visitar: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([[2,2], [0,0], [2,0], [0,2]])\n",
    "# y = np.array([1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Brother\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# Función para crear el perceptrón multicapa\n",
    "pmc = MLPClassifier(solver='lbfgs', alpha=1e-2, hidden_layer_sizes=(2,), activation='logistic', random_state=1)\n",
    "# Al llamar a fit se realiza el entrenamiento\n",
    "pmc.fit(X, y)\n",
    "\n",
    "y_p = pmc.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24592  8035]\n",
      " [ 6646 20727]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y, y_p)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# - Crear una función perceptron simple que dado un ejemplo o conjunto de ejemplos devuelva la clase predicha (-1, 1).\n",
    "def perceptron(x,w):\n",
    "    return np.sign(np.dot(x,w))\n",
    "# - Crear una función para calcular el coste 'bisagra' para medir el error en clasificación.\n",
    "def coste(X, y, w):\n",
    "    loss = 0\n",
    "    m = len(X)\n",
    "    for i in range(len(X)):\n",
    "        loss += max(1-(np.dot(w,X[i])*y[i]),0)        \n",
    "    return loss/m\n",
    "# - Crear una función que calcule el gradiente de la función de coste por cada variable del perceptrón.\n",
    "def gradientes(X,y,w):\n",
    "    m = len(X)\n",
    "    ws = []\n",
    "    dot = np.dot(X,w)*y <1\n",
    "    for i in range(len(w)):\n",
    "        nw = 0\n",
    "        nw = np.dot(-X[:,i]*dot,y)\n",
    "        ws.append(nw/m)        \n",
    "    return np.array(ws)\n",
    "# - Programar el algortimo del descenso con gradiente y obtener los parámetros del perceptrón que mejor se ajusten a los datos de entrenamiento.\n",
    "import matplotlib.pyplot as plt \n",
    "def DescensoGradiente(X, y, w_ini, alpha = 0.1, iters = 100):\n",
    "    w = w_ini\n",
    "    Loss = []\n",
    "    for i in range(iters):\n",
    "        grad = gradientes(X,y,w)\n",
    "        for j in range(len(w)):\n",
    "            w[j] = w[j] - (alpha*grad[j]) \n",
    "        Loss.append(coste(X,y, w))\n",
    "    return Loss,w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_ini = [1 for i in range(X_train.shape[1]+1)]\n",
    "print(w_ini)\n",
    "X_train_ones = np.concatenate((np.ones((X_train.shape[0],1)),X_train),axis=1)\n",
    "L,w = DescensoGradiente(X_train_ones,y_train,w_ini,0.005,200)\n",
    "\n",
    "plt.plot(L)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16669  9437]\n",
      " [ 7633 14261]]\n",
      "0.644375\n"
     ]
    }
   ],
   "source": [
    "ypred= perceptron(X_train_ones,w)\n",
    "cm = confusion_matrix(y_train, ypred)\n",
    "print(cm)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_train,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4150 2371]\n",
      " [1852 3627]]\n",
      "0.6480833333333333\n"
     ]
    }
   ],
   "source": [
    "# - Calcular la matriz de confusión en los ejemplos de test.\n",
    "X_test_ones = np.concatenate((np.ones((X_test.shape[0],1)),X_test),axis=1)\n",
    "ypred2= perceptron(X_test_ones,w)\n",
    "cm1 = confusion_matrix(y_test, ypred2)\n",
    "print(cm1)\n",
    "print(accuracy_score(y_test,ypred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4689 1832]\n",
      " [1089 4390]]\n",
      "[[4985 1536]\n",
      " [1361 4118]]\n"
     ]
    }
   ],
   "source": [
    "# - Utilizando la librería sklearn entrenar 2 arquitecturas diferentes de redes neuronales.\n",
    "\n",
    "##RED NEURONAL CON 2 CAPAS\n",
    "pmc = MLPClassifier(solver='sgd', alpha=.5e-2, hidden_layer_sizes=(2,), activation='logistic', random_state=1,max_iter=400)\n",
    "pmc.fit(X_train, y_train)\n",
    "y_p = pmc.predict(X_test)\n",
    "cm2 = confusion_matrix(y_test, y_p)\n",
    "print(cm2)\n",
    "\n",
    "##RED NEURONAL CON 4 CAPAS\n",
    "pmc = MLPClassifier(solver='sgd', alpha=.5e-2, hidden_layer_sizes=(4,), activation='logistic', random_state=1,max_iter=400)\n",
    "pmc.fit(X_train, y_train)\n",
    "y_p = pmc.predict(X_test)\n",
    "cm3 = confusion_matrix(y_test, y_p)\n",
    "print(cm3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El recall del perceptron simple es:  0.6619821135243658\n",
      "El recall de la primera neurona multicapa:  0.8012411023909473\n",
      "El recall de la segunda neurona multicapa:  0.7515970067530571\n",
      "La accuracy del perceptron simple es:  0.6480833333333333\n",
      "La accuracy de la primera neurona multicapa:  0.7565833333333334\n",
      "La accuracy de la segunda neurona multicapa:  0.7585833333333334\n",
      "La precision del perceptron simple es:  0.604701567189063\n",
      "La precision de la primera neurona multicapa:  0.7055609128897461\n",
      "La precision de la segunda neurona multicapa:  0.728333922886452\n",
      "El TNR del perceptron simple es:  0.6364054592853857\n",
      "El TNR de la primera neurona multicapa:  0.7190614936359454\n",
      "El TNR de la segunda neurona multicapa:  0.7644533047078669\n"
     ]
    }
   ],
   "source": [
    "# - Comparar las matrices de confusión de las Redes Neuronales con la obtenida por el perceptrón.\n",
    "\n",
    "##Dado que estamos comparando la eficacia para predecir el riesgo de padecer una enfermedad cardiaca, lo que de verdad nos\n",
    "##importa son los falsos negativos, es decir, la gente que vaya a padecer una enfermedad cardiaca y hayamos predecido que\n",
    "##no iba a padecerla.Para comparar los falssos negativos utilizaremos una funcion que los  funcion recall\n",
    "print(\"El recall del perceptron simple es: \",recall(cm1))\n",
    "print(\"El recall de la primera neurona multicapa: \",recall(cm2))\n",
    "print(\"El recall de la segunda neurona multicapa: \",recall(cm3))\n",
    "##Como podemos observar, la primera neurona tiene un valor mas grande por lo que tiene menos falsos negativos y sera \n",
    "##mas eficiente en este problema si cambiamos el umbral\n",
    "print(\"La accuracy del perceptron simple es: \",accuracy(cm1))\n",
    "print(\"La accuracy de la primera neurona multicapa: \",accuracy(cm2))\n",
    "print(\"La accuracy de la segunda neurona multicapa: \",accuracy(cm3))\n",
    "##En este caso las dos neuronas tienen resultados muy parecidos, mayores a los del perceptron simple.q\n",
    "print(\"La precision del perceptron simple es: \",precision(cm1))\n",
    "print(\"La precision de la primera neurona multicapa: \",precision(cm2))\n",
    "print(\"La precision de la segunda neurona multicapa: \",precision(cm3))\n",
    "##La mayor precision la tiene de nuevo la segunda neurona\n",
    "print(\"El TNR del perceptron simple es: \",TNR(cm1))\n",
    "print(\"El TNR de la primera neurona multicapa: \",TNR(cm2))\n",
    "print(\"El TNR de la segunda neurona multicapa: \",TNR(cm3))\n",
    "##Observando todos los parametros,podemos concluir que es mas efectivo utilizar una neurona multicapa ya que todos \n",
    "##sus parametros son mayores que los del perceptron simple.Esto quiere decir que acertara mas dado que tiene menos falsos\n",
    "##negativos y menos falsos positivos.Dentro de los dos tipos de neuronas multicapas, la segunda con mas capas acierta aun \n",
    "##mas que la primera por lo que seria mas eficiente elegir ese metodo.\n",
    "\n",
    "##Una posible mejora seria aumentar el umbral que en este caso es 0 para lo que tendriamos que utilizar un predictor de \n",
    "##probabilidad para valorar si esta por encima o por debajo del umbral.\n",
    "\n",
    "#            ¿se podría utilizar esta IA como un robo-doctor? \n",
    "#Si porque despues de entrenar a la IA podria llegar un paciente con determinadas caracteristicas y podria predecir si \n",
    "#tiene riesgo de padecer una enfermedad cardiaca.De hecho ya se ha visto que hay modelos IA que pueden predecir la \n",
    "#probabilidad de tener algun tipo de enfermedad mental solo con la informacion de las redes sociales\n",
    "#mejor que los propios especialistas en ese area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#los valores de la  matriz estan intercambiados comparando con el metodo que se usa en teoria dado que la libreria de Sklearn\n",
    "#utiliza la matriz transpuesta\n",
    "def accuracy(m):\n",
    "    VP = m[1][1]\n",
    "    FP = m[0][1]\n",
    "    FN = m[1][0]\n",
    "    VN = m[0][0]\n",
    "    return (VP+VN)/(VP+FP+VN+FN)\n",
    "def recall(m):\n",
    "    VP = m[1][1]\n",
    "    FP = m[0][1]\n",
    "    FN = m[1][0]\n",
    "    VN = m[0][0]\n",
    "    return (VP)/(VP+FN)\n",
    "def precision(m):\n",
    "    VP = m[1][1]\n",
    "    FP = m[0][1]\n",
    "    FN = m[1][0]\n",
    "    VN = m[0][0]\n",
    "    return (VP)/(VP+FP)\n",
    "def TNR(m):\n",
    "    VP = m[1][1]\n",
    "    FP = m[0][1]\n",
    "    FN = m[1][0]\n",
    "    VN = m[0][0]\n",
    "    return VN/(VN+FP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = [[1,0,2],[1,-2,0],[1,1,-1]]\n",
    "# y = [1,1,-1]\n",
    "# w = [0,0.5,1]\n",
    "# X = np.array(X)\n",
    "# w = np.array(w)\n",
    "# y = np.array(y)\n",
    "# print(coste(X,y,w))\n",
    "# print(gradientes(X,y,w))\n",
    "# print(DescensoGradiente(X,y,w,1,1))\n",
    "\n",
    "#EJEMPLO DE CLASE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
